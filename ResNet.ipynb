{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNet.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM072Jie+nsQ7HbosUuuZAR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ByOlkKwvL228","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623229419787,"user_tz":-540,"elapsed":16343,"user":{"displayName":"이유민","photoUrl":"","userId":"14631073475001434536"}},"outputId":"fbab18b6-f286-47c5-e1cc-8101cd487a25"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SzwHH_WNL4bp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623229429582,"user_tz":-540,"elapsed":264,"user":{"displayName":"이유민","photoUrl":"","userId":"14631073475001434536"}},"outputId":"271ae245-475d-47d8-ec8f-e00f6f527012"},"source":["cd /content/drive/My Drive/myModel"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/myModel\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qc_9hoh5L8jr","executionInfo":{"status":"ok","timestamp":1623229434439,"user_tz":-540,"elapsed":3260,"user":{"displayName":"이유민","photoUrl":"","userId":"14631073475001434536"}}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib as plt\n","from sklearn.model_selection import train_test_split\n","import sklearn\n","import resnet\n","import os\n","from keras.callbacks import EarlyStopping\n","import keras"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OgC52EYVpqzv"},"source":["## **데이터 불러오기**"]},{"cell_type":"markdown","metadata":{"id":"FKo5t3HuFVB4"},"source":["#### train set과 test set 을 따로 만들었을 경우에는 이 코드를 사용"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0IHSLbvxA_y0","executionInfo":{"status":"ok","timestamp":1623230742666,"user_tz":-540,"elapsed":635,"user":{"displayName":"이유민","photoUrl":"","userId":"14631073475001434536"}},"outputId":"d39b8412-de99-4f63-e98d-f83e200c2ae8"},"source":["train_data = np.loadtxt('./train.csv', delimiter=',')\n","test_data = np.loadtxt('./test.csv', delimiter=',')\n","\n","x_train = train_data[:,1:]\n","y_train = train_data[:,0]\n","x_test = test_data[:,1:]\n","y_test = test_data[:,0]\n","\n","# znorm\n","std_ = x_train.std(axis=1, keepdims=True)\n","std_[std_ == 0] = 1.0\n","x_train = (x_train - x_train.mean(axis=1, keepdims=True)) / std_\n","std_ = x_test.std(axis=1, keepdims=True)\n","std_[std_ == 0] = 1.0\n","x_test = (x_test - x_test.mean(axis=1, keepdims=True)) / std_\n","\n","print(\"x_train:\", x_train.shape)\n","print(\"x_test: \", x_test.shape)\n","print(\"y_train\", y_train.shape)\n","print(\"y_test: \", y_test.shape)"],"execution_count":30,"outputs":[{"output_type":"stream","text":["x_train: (270, 1000)\n","x_test:  (120, 1000)\n","y_train (270,)\n","y_test:  (120,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fNRpgMOyFe7M"},"source":["#### 전체 dataset에서 케라스가 알아서 train과 test로 나누고 싶을 때 이 코드 사용"]},{"cell_type":"code","metadata":{"id":"ZZZSyjP2L49w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622774388463,"user_tz":-540,"elapsed":7096,"user":{"displayName":"이유민","photoUrl":"","userId":"14631073475001434536"}},"outputId":"0b793f5e-3dc6-4c57-80b4-21a218311c4f"},"source":["def read_dataset(root_dir, dataset_name):\n","    datasets_dict = {}\n","\n","    df = np.loadtxt('./ALL_data.csv', delimiter=',')\n","\n","    x_train, x_test, y_train, y_test = train_test_split(df[:,1:], df[:,0], test_size=0.3)\n","    print(\"x_train:\", x_train.shape)\n","    print(\"x_test: \", x_test.shape)\n","    print(\"y_train\", y_train.shape)\n","    print(\"y_test: \", y_test.shape)\n","\n","    # znorm\n","    std_ = x_train.std(axis=1, keepdims=True)\n","    std_[std_ == 0] = 1.0\n","    x_train = (x_train - x_train.mean(axis=1, keepdims=True)) / std_\n","    std_ = x_test.std(axis=1, keepdims=True)\n","    std_[std_ == 0] = 1.0\n","    x_test = (x_test - x_test.mean(axis=1, keepdims=True)) / std_\n","    datasets_dict[dataset_name] = (x_train.copy(), y_train.copy(), x_test.copy(),\n","                                    y_test.copy())\n","    return datasets_dict\n","\n","datasets_dict= read_dataset('', 'handcream')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["x_train: (1770, 2000)\n","x_test:  (759, 2000)\n","y_train (1770,)\n","y_test:  (759,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EyL9DQNxpvCm"},"source":["## **폴더 만들기**\n","#### 모델 실행 후 만들어질 파일들이 저장될거임"]},{"cell_type":"code","metadata":{"id":"UGZS47E3oAbF","executionInfo":{"status":"ok","timestamp":1623230744810,"user_tz":-540,"elapsed":5,"user":{"displayName":"이유민","photoUrl":"","userId":"14631073475001434536"}}},"source":["def create_directory(directory_path):\n","    if os.path.exists(directory_path):\n","        return None\n","    else:\n","        try:\n","            os.makedirs(directory_path)\n","        except:\n","            return None\n","        return directory_path"],"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k5AdRHVPAGwt"},"source":["## **원핫인코딩**"]},{"cell_type":"code","metadata":{"id":"W-gxVD-f2lNw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623230747225,"user_tz":-540,"elapsed":269,"user":{"displayName":"이유민","photoUrl":"","userId":"14631073475001434536"}},"outputId":"6d3fe671-345c-420f-9f36-e9592f58e2dc"},"source":["dataset_name = 'handcream'\n","\n","# x_train = datasets_dict[dataset_name][0]\n","# y_train = datasets_dict[dataset_name][1]\n","# x_test = datasets_dict[dataset_name][2]\n","# y_test = datasets_dict[dataset_name][3]\n","print(\"x_train:\", x_train.shape)\n","print(\"x_test: \", x_test.shape)\n","print(\"y_train\", y_train.shape)\n","print(\"y_test: \", y_test.shape)\n","\n","nb_classes = len(np.unique(np.concatenate((y_train, y_test), axis=0)))\n","print(\"class:\", nb_classes)\n","enc = sklearn.preprocessing.OneHotEncoder(categories='auto')\n","enc.fit(np.concatenate((y_train, y_test), axis=0).reshape(-1, 1))\n","y_train = enc.transform(y_train.reshape(-1, 1)).toarray()\n","y_test = enc.transform(y_test.reshape(-1, 1)).toarray()\n","\n","y_true = np.argmax(y_test, axis=1)\n","\n","if len(x_train.shape) == 2:\n","    x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n","    x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n","\n","input_shape = x_train.shape[1:]\n","\n","output_directory = './resnet_' + dataset_name + '/'\n","create_directory(output_directory)"],"execution_count":32,"outputs":[{"output_type":"stream","text":["x_train: (270, 1000)\n","x_test:  (120, 1000)\n","y_train (270,)\n","y_test:  (120,)\n","class: 3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9g9npNtgBOAi"},"source":["## **ResNet 모델**"]},{"cell_type":"code","metadata":{"id":"czj_f5QY1Tnm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623230943152,"user_tz":-540,"elapsed":677,"user":{"displayName":"이유민","photoUrl":"","userId":"14631073475001434536"}},"outputId":"88cb332b-9bc6-437e-f831-7962fcf1b11b"},"source":["n_feature_maps = 64\n","\n","input_layer = keras.layers.Input(input_shape)\n","\n","# BLOCK 1\n","\n","conv_x = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=32, padding='same')(input_layer) #8\n","conv_x = keras.layers.BatchNormalization()(conv_x)\n","conv_x = keras.layers.Activation('relu')(conv_x)\n","\n","conv_y = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=16, padding='same')(conv_x) #5\n","conv_y = keras.layers.BatchNormalization()(conv_y)\n","conv_y = keras.layers.Activation('relu')(conv_y)\n","\n","conv_z = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=8, padding='same')(conv_y) #3\n","conv_z = keras.layers.BatchNormalization()(conv_z)\n","\n","# expand channels for the sum\n","shortcut_y = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=1, padding='same')(input_layer)\n","shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n","\n","output_block_1 = keras.layers.add([shortcut_y, conv_z])\n","output_block_1 = keras.layers.Activation('relu')(output_block_1)\n","\n","# BLOCK 2\n","\n","conv_x = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=32, padding='same')(output_block_1)\n","conv_x = keras.layers.BatchNormalization()(conv_x)\n","conv_x = keras.layers.Activation('relu')(conv_x)\n","\n","conv_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=16, padding='same')(conv_x)\n","conv_y = keras.layers.BatchNormalization()(conv_y)\n","conv_y = keras.layers.Activation('relu')(conv_y)\n","\n","conv_z = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=8, padding='same')(conv_y)\n","conv_z = keras.layers.BatchNormalization()(conv_z)\n","\n","# expand channels for the sum\n","shortcut_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=1, padding='same')(output_block_1)\n","shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n","\n","output_block_2 = keras.layers.add([shortcut_y, conv_z])\n","print(\"output_block_2:\", output_block_2)\n","output_block_2 = keras.layers.Activation('relu')(output_block_2)\n","\n","# BLOCK 3\n","\n","conv_x = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=32, padding='same')(output_block_2)\n","conv_x = keras.layers.BatchNormalization()(conv_x)\n","conv_x = keras.layers.Activation('relu')(conv_x)\n","\n","conv_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=16, padding='same')(conv_x)\n","conv_y = keras.layers.BatchNormalization()(conv_y)\n","conv_y = keras.layers.Activation('relu')(conv_y)\n","\n","conv_z = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=8, padding='same')(conv_y)\n","conv_z = keras.layers.BatchNormalization()(conv_z)\n","\n","# no need to expand channels because they are equal\n","shortcut_y = keras.layers.BatchNormalization()(output_block_2)\n","\n","output_block_3 = keras.layers.add([shortcut_y, conv_z])\n","output_block_3 = keras.layers.Activation('relu')(output_block_3)\n","# FINAL\n","\n","gap_layer = keras.layers.GlobalAveragePooling1D()(output_block_3)\n","output_layer = keras.layers.Dense(nb_classes, activation='softmax')(gap_layer)\n","\n","model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n","\n","model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(),\n","                metrics=['accuracy'])\n","\n","reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50, min_lr=0.0001)\n","\n","file_path = output_directory + 'best_model.hdf5'\n","\n","early_stopping_callback = EarlyStopping(monitor = 'loss', mode='min', patience=20, verbose=1)\n","\n","model_checkpoint = keras.callbacks.ModelCheckpoint(filepath=file_path, monitor='loss',\n","                                                    save_best_only=True)\n","\n","callbacks = [reduce_lr, model_checkpoint, early_stopping_callback]\n"],"execution_count":36,"outputs":[{"output_type":"stream","text":["output_block_2: KerasTensor(type_spec=TensorSpec(shape=(None, 1000, 128), dtype=tf.float32, name=None), name='add_7/add:0', description=\"created by layer 'add_7'\")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d99T-38h3y5l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623230944982,"user_tz":-540,"elapsed":253,"user":{"displayName":"이유민","photoUrl":"","userId":"14631073475001434536"}},"outputId":"42b32485-aee3-44cf-e95f-3032d4b8f15d"},"source":["model.summary()"],"execution_count":37,"outputs":[{"output_type":"stream","text":["Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            [(None, 1000, 1)]    0                                            \n","__________________________________________________________________________________________________\n","conv1d_22 (Conv1D)              (None, 1000, 64)     2112        input_3[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 1000, 64)     256         conv1d_22[0][0]                  \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 1000, 64)     0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_23 (Conv1D)              (None, 1000, 64)     65600       activation_18[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 1000, 64)     256         conv1d_23[0][0]                  \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 1000, 64)     0           batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_25 (Conv1D)              (None, 1000, 64)     128         input_3[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_24 (Conv1D)              (None, 1000, 64)     32832       activation_19[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 1000, 64)     256         conv1d_25[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 1000, 64)     256         conv1d_24[0][0]                  \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 1000, 64)     0           batch_normalization_27[0][0]     \n","                                                                 batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 1000, 64)     0           add_6[0][0]                      \n","__________________________________________________________________________________________________\n","conv1d_26 (Conv1D)              (None, 1000, 128)    262272      activation_20[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, 1000, 128)    512         conv1d_26[0][0]                  \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 1000, 128)    0           batch_normalization_28[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_27 (Conv1D)              (None, 1000, 128)    262272      activation_21[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 1000, 128)    512         conv1d_27[0][0]                  \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 1000, 128)    0           batch_normalization_29[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_29 (Conv1D)              (None, 1000, 128)    8320        activation_20[0][0]              \n","__________________________________________________________________________________________________\n","conv1d_28 (Conv1D)              (None, 1000, 128)    131200      activation_22[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, 1000, 128)    512         conv1d_29[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 1000, 128)    512         conv1d_28[0][0]                  \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 1000, 128)    0           batch_normalization_31[0][0]     \n","                                                                 batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 1000, 128)    0           add_7[0][0]                      \n","__________________________________________________________________________________________________\n","conv1d_30 (Conv1D)              (None, 1000, 128)    524416      activation_23[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, 1000, 128)    512         conv1d_30[0][0]                  \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 1000, 128)    0           batch_normalization_32[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_31 (Conv1D)              (None, 1000, 128)    262272      activation_24[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_33 (BatchNo (None, 1000, 128)    512         conv1d_31[0][0]                  \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 1000, 128)    0           batch_normalization_33[0][0]     \n","__________________________________________________________________________________________________\n","conv1d_32 (Conv1D)              (None, 1000, 128)    131200      activation_25[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_35 (BatchNo (None, 1000, 128)    512         activation_23[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_34 (BatchNo (None, 1000, 128)    512         conv1d_32[0][0]                  \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 1000, 128)    0           batch_normalization_35[0][0]     \n","                                                                 batch_normalization_34[0][0]     \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 1000, 128)    0           add_8[0][0]                      \n","__________________________________________________________________________________________________\n","global_average_pooling1d_2 (Glo (None, 128)          0           activation_26[0][0]              \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 3)            387         global_average_pooling1d_2[0][0] \n","==================================================================================================\n","Total params: 1,688,131\n","Trainable params: 1,685,571\n","Non-trainable params: 2,560\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7G4nfSZ-B7g1"},"source":["## **학습**"]},{"cell_type":"code","metadata":{"id":"Yc1n0Eiu6K2g","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1623231020092,"user_tz":-540,"elapsed":71898,"user":{"displayName":"이유민","photoUrl":"","userId":"14631073475001434536"}},"outputId":"6f214ec6-f641-4005-d468-61c4b1cb2fe8"},"source":["# validation_split: train dataset에서 validation dataset으로 분리할 크기 \n","# 0.2 => 20%\n","history = model.fit(x_train, y_train, batch_size=16, epochs=100, validation_split=0.3, callbacks=callbacks)\n","self.model.save(output_directory + 'last_model.hdf5')"],"execution_count":38,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","12/12 [==============================] - 7s 161ms/step - loss: 0.6132 - accuracy: 0.5975 - val_loss: 14.3209 - val_accuracy: 0.3704\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/100\n","12/12 [==============================] - 1s 65ms/step - loss: 0.2535 - accuracy: 0.8889 - val_loss: 6.5689 - val_accuracy: 0.3704\n","Epoch 3/100\n","12/12 [==============================] - 1s 71ms/step - loss: 0.1617 - accuracy: 0.9466 - val_loss: 10.8373 - val_accuracy: 0.3704\n","Epoch 4/100\n","12/12 [==============================] - 1s 69ms/step - loss: 0.2099 - accuracy: 0.9398 - val_loss: 3.5891 - val_accuracy: 0.7531\n","Epoch 5/100\n","12/12 [==============================] - 1s 73ms/step - loss: 0.0785 - accuracy: 0.9763 - val_loss: 4.5135 - val_accuracy: 0.7531\n","Epoch 6/100\n","12/12 [==============================] - 1s 67ms/step - loss: 0.0876 - accuracy: 0.9748 - val_loss: 2.5404 - val_accuracy: 0.7407\n","Epoch 7/100\n","12/12 [==============================] - 1s 66ms/step - loss: 0.3162 - accuracy: 0.8924 - val_loss: 8.7316 - val_accuracy: 0.3704\n","Epoch 8/100\n","12/12 [==============================] - 1s 66ms/step - loss: 0.1333 - accuracy: 0.9647 - val_loss: 8.8854 - val_accuracy: 0.3704\n","Epoch 9/100\n","12/12 [==============================] - 1s 73ms/step - loss: 0.1034 - accuracy: 0.9812 - val_loss: 5.7045 - val_accuracy: 0.3704\n","Epoch 10/100\n","12/12 [==============================] - 1s 66ms/step - loss: 0.0943 - accuracy: 0.9710 - val_loss: 3.6265 - val_accuracy: 0.7160\n","Epoch 11/100\n","12/12 [==============================] - 1s 67ms/step - loss: 0.1256 - accuracy: 0.9727 - val_loss: 13.1058 - val_accuracy: 0.6914\n","Epoch 12/100\n","12/12 [==============================] - 1s 67ms/step - loss: 0.1079 - accuracy: 0.9538 - val_loss: 7.9638 - val_accuracy: 0.7531\n","Epoch 13/100\n","12/12 [==============================] - 1s 66ms/step - loss: 0.0577 - accuracy: 0.9881 - val_loss: 4.1830 - val_accuracy: 0.7531\n","Epoch 14/100\n","12/12 [==============================] - 1s 66ms/step - loss: 0.0726 - accuracy: 0.9943 - val_loss: 3.4862 - val_accuracy: 0.7531\n","Epoch 15/100\n","12/12 [==============================] - 1s 72ms/step - loss: 0.1217 - accuracy: 0.9528 - val_loss: 4.5253 - val_accuracy: 0.6296\n","Epoch 16/100\n","12/12 [==============================] - 1s 66ms/step - loss: 0.0579 - accuracy: 0.9850 - val_loss: 7.7683 - val_accuracy: 0.3457\n","Epoch 17/100\n","12/12 [==============================] - 1s 67ms/step - loss: 0.1454 - accuracy: 0.9040 - val_loss: 4.7020 - val_accuracy: 0.4198\n","Epoch 18/100\n","12/12 [==============================] - 1s 65ms/step - loss: 0.0618 - accuracy: 0.9818 - val_loss: 1.3612 - val_accuracy: 0.6049\n","Epoch 19/100\n","12/12 [==============================] - 1s 66ms/step - loss: 0.1162 - accuracy: 0.9565 - val_loss: 0.1851 - val_accuracy: 0.9630\n","Epoch 20/100\n","12/12 [==============================] - 1s 67ms/step - loss: 0.1950 - accuracy: 0.9240 - val_loss: 7.8375 - val_accuracy: 0.3704\n","Epoch 21/100\n","12/12 [==============================] - 1s 68ms/step - loss: 0.1838 - accuracy: 0.9330 - val_loss: 3.5117 - val_accuracy: 0.3704\n","Epoch 22/100\n","12/12 [==============================] - 1s 71ms/step - loss: 0.1079 - accuracy: 0.9580 - val_loss: 1.7389 - val_accuracy: 0.3704\n","Epoch 23/100\n","12/12 [==============================] - 1s 66ms/step - loss: 0.0436 - accuracy: 0.9911 - val_loss: 0.8979 - val_accuracy: 0.5556\n","Epoch 24/100\n","12/12 [==============================] - 1s 66ms/step - loss: 0.0596 - accuracy: 0.9888 - val_loss: 0.7912 - val_accuracy: 0.6173\n","Epoch 25/100\n","12/12 [==============================] - 1s 72ms/step - loss: 0.0572 - accuracy: 0.9812 - val_loss: 0.6082 - val_accuracy: 0.6173\n","Epoch 26/100\n","12/12 [==============================] - 1s 66ms/step - loss: 0.0618 - accuracy: 0.9803 - val_loss: 0.4343 - val_accuracy: 0.8889\n","Epoch 27/100\n","12/12 [==============================] - 1s 66ms/step - loss: 0.0607 - accuracy: 0.9832 - val_loss: 0.1725 - val_accuracy: 0.9383\n","Epoch 28/100\n","12/12 [==============================] - 1s 72ms/step - loss: 0.1130 - accuracy: 0.9612 - val_loss: 0.7771 - val_accuracy: 0.6667\n","Epoch 29/100\n","12/12 [==============================] - 1s 66ms/step - loss: 0.1302 - accuracy: 0.9566 - val_loss: 3.6538 - val_accuracy: 0.6173\n","Epoch 30/100\n","12/12 [==============================] - 1s 67ms/step - loss: 0.0715 - accuracy: 0.9700 - val_loss: 6.9144 - val_accuracy: 0.6173\n","Epoch 31/100\n","12/12 [==============================] - 1s 66ms/step - loss: 0.0996 - accuracy: 0.9539 - val_loss: 0.1102 - val_accuracy: 0.9506\n","Epoch 32/100\n","12/12 [==============================] - 1s 68ms/step - loss: 0.0877 - accuracy: 0.9679 - val_loss: 1.4518 - val_accuracy: 0.3951\n","Epoch 33/100\n","12/12 [==============================] - 1s 66ms/step - loss: 0.0261 - accuracy: 0.9971 - val_loss: 1.4319 - val_accuracy: 0.3704\n","Epoch 34/100\n","12/12 [==============================] - 1s 67ms/step - loss: 0.0399 - accuracy: 0.9903 - val_loss: 1.1392 - val_accuracy: 0.6173\n","Epoch 35/100\n","12/12 [==============================] - 1s 72ms/step - loss: 0.0593 - accuracy: 0.9870 - val_loss: 0.8019 - val_accuracy: 0.5926\n","Epoch 36/100\n","12/12 [==============================] - 1s 66ms/step - loss: 0.0434 - accuracy: 0.9854 - val_loss: 0.7333 - val_accuracy: 0.6420\n","Epoch 37/100\n","12/12 [==============================] - 1s 73ms/step - loss: 0.0729 - accuracy: 0.9756 - val_loss: 0.5079 - val_accuracy: 0.8395\n","Epoch 38/100\n","12/12 [==============================] - 1s 67ms/step - loss: 0.0468 - accuracy: 0.9888 - val_loss: 0.9100 - val_accuracy: 0.6420\n","Epoch 39/100\n","12/12 [==============================] - 1s 67ms/step - loss: 0.0575 - accuracy: 0.9691 - val_loss: 0.6974 - val_accuracy: 0.7284\n","Epoch 40/100\n","12/12 [==============================] - 1s 67ms/step - loss: 0.0589 - accuracy: 0.9861 - val_loss: 1.6110 - val_accuracy: 0.6296\n","Epoch 41/100\n","12/12 [==============================] - 1s 72ms/step - loss: 0.0422 - accuracy: 0.9960 - val_loss: 1.2984 - val_accuracy: 0.6296\n","Epoch 42/100\n","12/12 [==============================] - 1s 66ms/step - loss: 0.0336 - accuracy: 0.9885 - val_loss: 0.8833 - val_accuracy: 0.7284\n","Epoch 43/100\n","12/12 [==============================] - 1s 67ms/step - loss: 0.0373 - accuracy: 0.9786 - val_loss: 0.2338 - val_accuracy: 0.9012\n","Epoch 44/100\n","12/12 [==============================] - 1s 67ms/step - loss: 0.0138 - accuracy: 0.9960 - val_loss: 0.1693 - val_accuracy: 0.9259\n","Epoch 45/100\n","12/12 [==============================] - 1s 73ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.4358 - val_accuracy: 0.8395\n","Epoch 46/100\n","12/12 [==============================] - 1s 73ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.1550 - val_accuracy: 0.9012\n","Epoch 47/100\n","12/12 [==============================] - 1s 73ms/step - loss: 0.0303 - accuracy: 0.9894 - val_loss: 0.5281 - val_accuracy: 0.8148\n","Epoch 48/100\n","12/12 [==============================] - 1s 67ms/step - loss: 0.0310 - accuracy: 0.9919 - val_loss: 0.3207 - val_accuracy: 0.8889\n","Epoch 49/100\n","12/12 [==============================] - 1s 67ms/step - loss: 0.0193 - accuracy: 0.9971 - val_loss: 0.4860 - val_accuracy: 0.8519\n","Epoch 50/100\n","12/12 [==============================] - 1s 68ms/step - loss: 0.0209 - accuracy: 0.9956 - val_loss: 0.3682 - val_accuracy: 0.8642\n","Epoch 51/100\n","12/12 [==============================] - 1s 68ms/step - loss: 0.0195 - accuracy: 0.9992 - val_loss: 0.0426 - val_accuracy: 0.9877\n","Epoch 52/100\n","12/12 [==============================] - 1s 68ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.3405 - val_accuracy: 0.9012\n","Epoch 53/100\n","12/12 [==============================] - 1s 68ms/step - loss: 0.0204 - accuracy: 0.9983 - val_loss: 0.1107 - val_accuracy: 0.9506\n","Epoch 54/100\n","12/12 [==============================] - 1s 67ms/step - loss: 0.0353 - accuracy: 0.9867 - val_loss: 0.0547 - val_accuracy: 0.9877\n","Epoch 55/100\n","12/12 [==============================] - 1s 73ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n","Epoch 56/100\n","12/12 [==============================] - 1s 74ms/step - loss: 0.0173 - accuracy: 0.9992 - val_loss: 0.0556 - val_accuracy: 0.9753\n","Epoch 57/100\n","12/12 [==============================] - 1s 74ms/step - loss: 0.1050 - accuracy: 0.9455 - val_loss: 1.1869 - val_accuracy: 0.8025\n","Epoch 58/100\n","12/12 [==============================] - 1s 68ms/step - loss: 0.0432 - accuracy: 0.9853 - val_loss: 0.9381 - val_accuracy: 0.7531\n","Epoch 59/100\n","12/12 [==============================] - 1s 73ms/step - loss: 0.0164 - accuracy: 0.9987 - val_loss: 0.4496 - val_accuracy: 0.8642\n","Epoch 60/100\n","12/12 [==============================] - 1s 68ms/step - loss: 0.0308 - accuracy: 0.9992 - val_loss: 0.4693 - val_accuracy: 0.8519\n","Epoch 61/100\n","12/12 [==============================] - 1s 69ms/step - loss: 0.0188 - accuracy: 0.9975 - val_loss: 0.3207 - val_accuracy: 0.8765\n","Epoch 62/100\n","12/12 [==============================] - 1s 70ms/step - loss: 0.0761 - accuracy: 0.9716 - val_loss: 0.5276 - val_accuracy: 0.8148\n","Epoch 63/100\n","12/12 [==============================] - 1s 69ms/step - loss: 0.0528 - accuracy: 0.9802 - val_loss: 1.7000 - val_accuracy: 0.6296\n","Epoch 64/100\n","12/12 [==============================] - 1s 69ms/step - loss: 0.0290 - accuracy: 0.9955 - val_loss: 1.4772 - val_accuracy: 0.5926\n","Epoch 65/100\n","12/12 [==============================] - 1s 68ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 2.2325 - val_accuracy: 0.3704\n","Epoch 66/100\n","12/12 [==============================] - 1s 68ms/step - loss: 0.0240 - accuracy: 0.9913 - val_loss: 1.1553 - val_accuracy: 0.6543\n","Epoch 67/100\n","12/12 [==============================] - 1s 69ms/step - loss: 0.0185 - accuracy: 0.9935 - val_loss: 0.7457 - val_accuracy: 0.7654\n","Epoch 68/100\n","12/12 [==============================] - 1s 68ms/step - loss: 0.0389 - accuracy: 0.9846 - val_loss: 0.8328 - val_accuracy: 0.7407\n","Epoch 69/100\n","12/12 [==============================] - 1s 74ms/step - loss: 0.1566 - accuracy: 0.9544 - val_loss: 4.2053 - val_accuracy: 0.6173\n","Epoch 70/100\n","12/12 [==============================] - 1s 69ms/step - loss: 0.0695 - accuracy: 0.9708 - val_loss: 3.0634 - val_accuracy: 0.6173\n","Epoch 71/100\n","12/12 [==============================] - 1s 68ms/step - loss: 0.1361 - accuracy: 0.9553 - val_loss: 17.5528 - val_accuracy: 0.3704\n","Epoch 72/100\n","12/12 [==============================] - 1s 69ms/step - loss: 0.0832 - accuracy: 0.9834 - val_loss: 8.6872 - val_accuracy: 0.3704\n","Epoch 73/100\n","12/12 [==============================] - 1s 69ms/step - loss: 0.1243 - accuracy: 0.9568 - val_loss: 14.2994 - val_accuracy: 0.3704\n","Epoch 74/100\n","12/12 [==============================] - 1s 69ms/step - loss: 0.0705 - accuracy: 0.9724 - val_loss: 16.9243 - val_accuracy: 0.3704\n","Epoch 75/100\n","12/12 [==============================] - 1s 69ms/step - loss: 0.0256 - accuracy: 0.9992 - val_loss: 11.4705 - val_accuracy: 0.3704\n","Epoch 00075: early stopping\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-6f7cf179e4d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 0.2 => 20%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_directory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'last_model.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"yRNEd2fRETGm"},"source":["## **모델 평가**"]},{"cell_type":"code","metadata":{"id":"B7X0ktG4mYfg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623231055698,"user_tz":-540,"elapsed":4888,"user":{"displayName":"이유민","photoUrl":"","userId":"14631073475001434536"}},"outputId":"a443d003-49b2-40ff-b4e6-4c674e7073b7"},"source":["import matplotlib.pyplot as plt\n","import keras\n","import sklearn\n","\n","model_path = output_directory + 'best_model.hdf5'\n","model = keras.models.load_model(model_path)\n","\n","print(\"정확도 : %.2f \" %(model.evaluate(x_test, y_test)[1]))\n","\n","prediction = model.predict(x_test)\n","\n","for i in prediction:\n","    pre_ans = i.argmax()  # 예측 레이블\n","    print(i)\n","    print(pre_ans)\n","\n","y_pred = model.predict(x_test)\n","print(y_pred)\n","y_pred = np.argmax(y_pred, axis=1)"],"execution_count":39,"outputs":[{"output_type":"stream","text":["4/4 [==============================] - 1s 31ms/step - loss: 0.2297 - accuracy: 0.9083\n","정확도 : 0.91 \n","[1.4792218e-04 9.9896157e-01 8.9056639e-04]\n","1\n","[1.1922223e-05 9.9996793e-01 2.0180274e-05]\n","1\n","[9.99881387e-01 1.14341274e-04 4.33535251e-06]\n","0\n","[9.9154752e-01 8.4291175e-03 2.3431661e-05]\n","0\n","[9.996792e-01 3.129339e-04 7.842198e-06]\n","0\n","[9.993772e-01 5.448522e-04 7.808196e-05]\n","0\n","[4.7806323e-05 1.5801768e-04 9.9979419e-01]\n","2\n","[4.9650724e-05 9.9992943e-01 2.0866555e-05]\n","1\n","[9.1781667e-06 9.9996686e-01 2.3978198e-05]\n","1\n","[9.9833196e-01 1.6568702e-03 1.1203174e-05]\n","0\n","[0.00213858 0.97460073 0.02326066]\n","1\n","[2.4805146e-05 1.0269873e-04 9.9987245e-01]\n","2\n","[0.00546529 0.50929075 0.48524395]\n","1\n","[1.7183952e-04 1.6827103e-03 9.9814546e-01]\n","2\n","[0.00309009 0.8503266  0.14658336]\n","1\n","[9.8530654e-06 9.9998295e-01 7.1590621e-06]\n","1\n","[1.5891877e-04 9.9964118e-01 1.9979051e-04]\n","1\n","[3.3689651e-04 6.5553922e-04 9.9900764e-01]\n","2\n","[0.00102517 0.00430938 0.9946654 ]\n","2\n","[9.9951375e-01 4.2940155e-04 5.6783963e-05]\n","0\n","[9.7957039e-01 4.8522797e-04 1.9944385e-02]\n","0\n","[9.9950385e-01 4.3845101e-04 5.7620986e-05]\n","0\n","[1.4008124e-05 9.9997771e-01 8.2423130e-06]\n","1\n","[2.6931430e-06 9.9999499e-01 2.2380682e-06]\n","1\n","[9.9940908e-01 5.1732216e-04 7.3622177e-05]\n","0\n","[9.9998605e-01 1.3266873e-05 7.7305646e-07]\n","0\n","[1.0101854e-05 8.2899132e-06 9.9998164e-01]\n","2\n","[3.5518377e-05 9.2133363e-05 9.9987233e-01]\n","2\n","[1.03840815e-04 9.99605119e-01 2.91101343e-04]\n","1\n","[5.5804651e-04 9.9617416e-01 3.2679073e-03]\n","1\n","[9.9994087e-01 5.6868019e-05 2.2798156e-06]\n","0\n","[3.8352344e-05 9.9981171e-01 1.4994942e-04]\n","1\n","[2.9761100e-04 1.2440893e-02 9.8726153e-01]\n","2\n","[9.9942625e-01 4.9700309e-04 7.6772019e-05]\n","0\n","[2.3738045e-04 9.9910551e-01 6.5709447e-04]\n","1\n","[2.3399749e-04 9.9818462e-01 1.5814245e-03]\n","1\n","[1.3160691e-04 2.4999527e-04 9.9961841e-01]\n","2\n","[9.9952853e-01 4.6267867e-04 8.8538745e-06]\n","0\n","[0.00137433 0.97338176 0.02524392]\n","1\n","[9.9915922e-01 8.3161093e-04 9.1484435e-06]\n","0\n","[0.00423723 0.71953917 0.27622363]\n","1\n","[0.00110188 0.00656656 0.9923315 ]\n","2\n","[9.99087930e-01 8.97594844e-04 1.45111335e-05]\n","0\n","[4.6287794e-05 9.9992704e-01 2.6728456e-05]\n","1\n","[9.9976414e-01 2.3027216e-04 5.6521717e-06]\n","0\n","[9.9460536e-01 5.3469660e-03 4.7698883e-05]\n","0\n","[1.0291034e-04 1.0240527e-04 9.9979466e-01]\n","2\n","[1.9305917e-04 9.9764270e-01 2.1642325e-03]\n","1\n","[1.5685289e-05 9.9997783e-01 6.4086794e-06]\n","1\n","[1.3363101e-04 9.9914682e-01 7.1950431e-04]\n","1\n","[4.6937723e-05 5.2164287e-05 9.9990094e-01]\n","2\n","[0.00086618 0.8009954  0.19813842]\n","1\n","[1.3089245e-04 3.2201342e-04 9.9954706e-01]\n","2\n","[9.9510962e-01 4.8669134e-03 2.3502722e-05]\n","0\n","[6.85244061e-07 9.99999166e-01 1.15813165e-07]\n","1\n","[9.9972600e-01 2.4710366e-04 2.6987978e-05]\n","0\n","[0.00201981 0.93758345 0.06039676]\n","1\n","[9.9978846e-01 2.0862889e-04 2.9216578e-06]\n","0\n","[9.9996984e-01 2.7698994e-05 2.4456178e-06]\n","0\n","[1.06453765e-04 9.99630690e-01 2.62865971e-04]\n","1\n","[9.9995136e-01 4.1484611e-05 7.2062981e-06]\n","0\n","[9.9998093e-01 1.7676619e-05 1.3916432e-06]\n","0\n","[4.1804447e-05 9.9990690e-01 5.1240015e-05]\n","1\n","[9.9914896e-01 7.3418021e-04 1.1687350e-04]\n","0\n","[2.3638523e-04 8.2315732e-04 9.9894041e-01]\n","2\n","[9.9983573e-01 1.5810505e-04 6.1652245e-06]\n","0\n","[0.0022445  0.05765212 0.94010335]\n","2\n","[1.5063329e-06 9.9999797e-01 4.6096179e-07]\n","1\n","[0.00338349 0.4328673  0.56374925]\n","2\n","[3.3167645e-04 9.9690634e-01 2.7619957e-03]\n","1\n","[4.6927558e-05 9.9986660e-01 8.6356216e-05]\n","1\n","[9.9987745e-01 1.1044742e-04 1.1991269e-05]\n","0\n","[9.9953175e-01 4.6022676e-04 8.1565267e-06]\n","0\n","[9.9714643e-01 2.8390456e-03 1.4493864e-05]\n","0\n","[2.5198649e-05 1.9400839e-04 9.9978083e-01]\n","2\n","[8.2694700e-05 1.1914501e-04 9.9979824e-01]\n","2\n","[0.0012632  0.10821253 0.8905243 ]\n","2\n","[0.00142947 0.08264378 0.9159267 ]\n","2\n","[2.8415398e-05 2.3386255e-04 9.9973768e-01]\n","2\n","[9.9997473e-01 1.8064675e-05 7.2000576e-06]\n","0\n","[1.9397012e-05 7.9916783e-05 9.9990070e-01]\n","2\n","[9.9957830e-01 3.7285220e-04 4.8831647e-05]\n","0\n","[4.7895164e-06 9.9999380e-01 1.4496372e-06]\n","1\n","[9.9984634e-01 1.4675877e-04 6.8614722e-06]\n","0\n","[3.0782438e-05 9.9993205e-01 3.7211601e-05]\n","1\n","[5.0545536e-06 9.9999034e-01 4.6196806e-06]\n","1\n","[0.00379202 0.4259001  0.57030785]\n","2\n","[1.6651987e-04 9.9899215e-01 8.4137928e-04]\n","1\n","[0.00286383 0.645435   0.35170117]\n","1\n","[9.9950790e-01 4.6184674e-04 3.0299452e-05]\n","0\n","[9.9977213e-01 2.1803462e-04 9.9142653e-06]\n","0\n","[9.9947172e-01 5.1330746e-04 1.5052739e-05]\n","0\n","[4.1972082e-05 9.9992716e-01 3.0826177e-05]\n","1\n","[9.9959451e-01 3.5868527e-04 4.6881421e-05]\n","0\n","[5.2678846e-05 9.9977392e-01 1.7335605e-04]\n","1\n","[0.0018186  0.9851923  0.01298903]\n","1\n","[2.3130301e-04 9.9859947e-01 1.1691974e-03]\n","1\n","[2.4936764e-05 6.7114182e-05 9.9990797e-01]\n","2\n","[0.00222447 0.22335653 0.774419  ]\n","2\n","[0.00231308 0.98502594 0.01266091]\n","1\n","[3.3592514e-04 9.9883407e-01 8.3003863e-04]\n","1\n","[6.8268849e-04 9.4882798e-01 5.0489306e-02]\n","1\n","[2.2619271e-05 6.2842213e-05 9.9991453e-01]\n","2\n","[1.1182620e-06 9.9999869e-01 2.8149685e-07]\n","1\n","[9.9980575e-01 1.7598065e-04 1.8253120e-05]\n","0\n","[1.7083374e-04 9.9803942e-01 1.7897009e-03]\n","1\n","[9.9977320e-01 1.8302859e-04 4.3732245e-05]\n","0\n","[0.00431325 0.3938285  0.60185826]\n","2\n","[9.9441272e-01 5.5672494e-03 1.9975194e-05]\n","0\n","[5.2760938e-06 9.9999154e-01 3.2298008e-06]\n","1\n","[9.668349e-05 7.639051e-04 9.991394e-01]\n","2\n","[0.00198124 0.835497   0.1625218 ]\n","1\n","[3.8381258e-04 9.9221438e-01 7.4017416e-03]\n","1\n","[9.9952686e-01 4.6788811e-04 5.2778737e-06]\n","0\n","[0.00147808 0.96552736 0.03299456]\n","1\n","[2.5521981e-04 9.9817693e-01 1.5678662e-03]\n","1\n","[6.158031e-05 9.821926e-04 9.989562e-01]\n","2\n","[0.00451394 0.19665611 0.7988299 ]\n","2\n","[9.9991536e-01 4.9758331e-05 3.4893696e-05]\n","0\n","[0.00151549 0.14514372 0.8533408 ]\n","2\n","[[1.47922183e-04 9.98961568e-01 8.90566385e-04]\n"," [1.19222232e-05 9.99967933e-01 2.01802741e-05]\n"," [9.99881387e-01 1.14341274e-04 4.33535251e-06]\n"," [9.91547525e-01 8.42911750e-03 2.34316612e-05]\n"," [9.99679208e-01 3.12933902e-04 7.84219810e-06]\n"," [9.99377191e-01 5.44852228e-04 7.80819610e-05]\n"," [4.78063230e-05 1.58017676e-04 9.99794185e-01]\n"," [4.96507237e-05 9.99929428e-01 2.08665551e-05]\n"," [9.17816669e-06 9.99966860e-01 2.39781984e-05]\n"," [9.98331964e-01 1.65687024e-03 1.12031739e-05]\n"," [2.13857717e-03 9.74600732e-01 2.32606623e-02]\n"," [2.48051456e-05 1.02698730e-04 9.99872446e-01]\n"," [5.46529330e-03 5.09290755e-01 4.85243946e-01]\n"," [1.71839521e-04 1.68271025e-03 9.98145461e-01]\n"," [3.09009338e-03 8.50326598e-01 1.46583363e-01]\n"," [9.85306542e-06 9.99982953e-01 7.15906208e-06]\n"," [1.58918774e-04 9.99641180e-01 1.99790506e-04]\n"," [3.36896512e-04 6.55539217e-04 9.99007642e-01]\n"," [1.02517358e-03 4.30938229e-03 9.94665384e-01]\n"," [9.99513745e-01 4.29401553e-04 5.67839634e-05]\n"," [9.79570389e-01 4.85227967e-04 1.99443847e-02]\n"," [9.99503851e-01 4.38451010e-04 5.76209859e-05]\n"," [1.40081238e-05 9.99977708e-01 8.24231302e-06]\n"," [2.69314296e-06 9.99994993e-01 2.23806819e-06]\n"," [9.99409080e-01 5.17322158e-04 7.36221773e-05]\n"," [9.99986053e-01 1.32668729e-05 7.73056456e-07]\n"," [1.01018541e-05 8.28991324e-06 9.99981642e-01]\n"," [3.55183765e-05 9.21333631e-05 9.99872327e-01]\n"," [1.03840815e-04 9.99605119e-01 2.91101343e-04]\n"," [5.58046508e-04 9.96174157e-01 3.26790730e-03]\n"," [9.99940872e-01 5.68680189e-05 2.27981559e-06]\n"," [3.83523438e-05 9.99811709e-01 1.49949425e-04]\n"," [2.97610997e-04 1.24408929e-02 9.87261534e-01]\n"," [9.99426246e-01 4.97003086e-04 7.67720194e-05]\n"," [2.37380445e-04 9.99105513e-01 6.57094468e-04]\n"," [2.33997489e-04 9.98184621e-01 1.58142450e-03]\n"," [1.31606910e-04 2.49995268e-04 9.99618411e-01]\n"," [9.99528527e-01 4.62678669e-04 8.85387453e-06]\n"," [1.37433410e-03 9.73381758e-01 2.52439156e-02]\n"," [9.99159217e-01 8.31610931e-04 9.14844350e-06]\n"," [4.23723226e-03 7.19539165e-01 2.76223630e-01]\n"," [1.10188080e-03 6.56656222e-03 9.92331505e-01]\n"," [9.99087930e-01 8.97594844e-04 1.45111335e-05]\n"," [4.62877942e-05 9.99927044e-01 2.67284559e-05]\n"," [9.99764144e-01 2.30272155e-04 5.65217169e-06]\n"," [9.94605362e-01 5.34696598e-03 4.76988826e-05]\n"," [1.02910337e-04 1.02405269e-04 9.99794662e-01]\n"," [1.93059168e-04 9.97642696e-01 2.16423254e-03]\n"," [1.56852893e-05 9.99977827e-01 6.40867938e-06]\n"," [1.33631009e-04 9.99146819e-01 7.19504314e-04]\n"," [4.69377228e-05 5.21642869e-05 9.99900937e-01]\n"," [8.66184477e-04 8.00995409e-01 1.98138416e-01]\n"," [1.30892455e-04 3.22013424e-04 9.99547064e-01]\n"," [9.95109618e-01 4.86691343e-03 2.35027219e-05]\n"," [6.85244061e-07 9.99999166e-01 1.15813165e-07]\n"," [9.99725997e-01 2.47103657e-04 2.69879783e-05]\n"," [2.01981305e-03 9.37583447e-01 6.03967570e-02]\n"," [9.99788463e-01 2.08628888e-04 2.92165782e-06]\n"," [9.99969840e-01 2.76989940e-05 2.44561784e-06]\n"," [1.06453765e-04 9.99630690e-01 2.62865971e-04]\n"," [9.99951363e-01 4.14846108e-05 7.20629805e-06]\n"," [9.99980927e-01 1.76766189e-05 1.39164320e-06]\n"," [4.18044474e-05 9.99906898e-01 5.12400147e-05]\n"," [9.99148965e-01 7.34180212e-04 1.16873503e-04]\n"," [2.36385225e-04 8.23157316e-04 9.98940408e-01]\n"," [9.99835730e-01 1.58105046e-04 6.16522448e-06]\n"," [2.24449579e-03 5.76521195e-02 9.40103352e-01]\n"," [1.50633286e-06 9.99997973e-01 4.60961786e-07]\n"," [3.38348909e-03 4.32867289e-01 5.63749254e-01]\n"," [3.31676449e-04 9.96906340e-01 2.76199565e-03]\n"," [4.69275583e-05 9.99866605e-01 8.63562163e-05]\n"," [9.99877453e-01 1.10447421e-04 1.19912693e-05]\n"," [9.99531746e-01 4.60226758e-04 8.15652675e-06]\n"," [9.97146428e-01 2.83904560e-03 1.44938640e-05]\n"," [2.51986494e-05 1.94008389e-04 9.99780834e-01]\n"," [8.26946998e-05 1.19145006e-04 9.99798238e-01]\n"," [1.26320426e-03 1.08212531e-01 8.90524328e-01]\n"," [1.42946595e-03 8.26437846e-02 9.15926695e-01]\n"," [2.84153975e-05 2.33862549e-04 9.99737680e-01]\n"," [9.99974728e-01 1.80646748e-05 7.20005755e-06]\n"," [1.93970118e-05 7.99167829e-05 9.99900699e-01]\n"," [9.99578297e-01 3.72852199e-04 4.88316473e-05]\n"," [4.78951642e-06 9.99993801e-01 1.44963724e-06]\n"," [9.99846339e-01 1.46758772e-04 6.86147223e-06]\n"," [3.07824375e-05 9.99932051e-01 3.72116010e-05]\n"," [5.05455364e-06 9.99990344e-01 4.61968057e-06]\n"," [3.79202142e-03 4.25900102e-01 5.70307851e-01]\n"," [1.66519865e-04 9.98992145e-01 8.41379282e-04]\n"," [2.86382693e-03 6.45434976e-01 3.51701170e-01]\n"," [9.99507904e-01 4.61846736e-04 3.02994522e-05]\n"," [9.99772131e-01 2.18034620e-04 9.91426532e-06]\n"," [9.99471724e-01 5.13307459e-04 1.50527394e-05]\n"," [4.19720818e-05 9.99927163e-01 3.08261770e-05]\n"," [9.99594510e-01 3.58685269e-04 4.68814214e-05]\n"," [5.26788463e-05 9.99773920e-01 1.73356049e-04]\n"," [1.81859860e-03 9.85192299e-01 1.29890321e-02]\n"," [2.31303013e-04 9.98599470e-01 1.16919738e-03]\n"," [2.49367640e-05 6.71141825e-05 9.99907970e-01]\n"," [2.22447002e-03 2.23356530e-01 7.74419010e-01]\n"," [2.31308327e-03 9.85025942e-01 1.26609085e-02]\n"," [3.35925142e-04 9.98834074e-01 8.30038625e-04]\n"," [6.82688493e-04 9.48827982e-01 5.04893064e-02]\n"," [2.26192715e-05 6.28422131e-05 9.99914527e-01]\n"," [1.11826205e-06 9.99998689e-01 2.81496852e-07]\n"," [9.99805748e-01 1.75980647e-04 1.82531203e-05]\n"," [1.70833737e-04 9.98039424e-01 1.78970094e-03]\n"," [9.99773204e-01 1.83028591e-04 4.37322451e-05]\n"," [4.31325240e-03 3.93828511e-01 6.01858258e-01]\n"," [9.94412720e-01 5.56724938e-03 1.99751939e-05]\n"," [5.27609382e-06 9.99991536e-01 3.22980077e-06]\n"," [9.66834923e-05 7.63905118e-04 9.99139428e-01]\n"," [1.98124256e-03 8.35497022e-01 1.62521794e-01]\n"," [3.83812585e-04 9.92214382e-01 7.40174158e-03]\n"," [9.99526858e-01 4.67888109e-04 5.27787370e-06]\n"," [1.47808390e-03 9.65527356e-01 3.29945572e-02]\n"," [2.55219813e-04 9.98176932e-01 1.56786619e-03]\n"," [6.15803074e-05 9.82192578e-04 9.98956203e-01]\n"," [4.51394403e-03 1.96656108e-01 7.98829913e-01]\n"," [9.99915361e-01 4.97583314e-05 3.48936956e-05]\n"," [1.51548919e-03 1.45143718e-01 8.53340805e-01]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iyIjri8O5uEg"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f6fUTezeFoQe"},"source":["## **시각화**"]},{"cell_type":"code","metadata":{"id":"kOLCpQvCEadk"},"source":["plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['loss', 'val_loss', 'acc', 'val_acc'], loc='upper left')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FGq-UpmPvbhD"},"source":["plt.plot(history.history['loss'])\n","plt.savefig('loss.png')\n","plt.clf()\n","plt.plot(history.history['val_loss'])\n","plt.savefig('vloss.png')\n","plt.clf()\n","plt.plot(history.history['accuracy'])\n","plt.savefig('acc.png')\n","plt.clf()\n","plt.plot(history.history['val_accuracy'])\n","plt.savefig('vacc.png')\n","plt.clf()\n","# plt.title('model loss')\n","# plt.ylabel('loss')\n","# plt.xlabel('epoch')\n","# plt.legend(['loss', 'accuracy', 'val_accuracy'], loc='upper left')\n","# plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q8Onbau5DBJf"},"source":[""],"execution_count":null,"outputs":[]}]}
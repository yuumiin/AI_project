{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"torch_model.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":["j1VbjC8MBIOZ","ndKIIWQOBhad"],"authorship_tag":"ABX9TyM4OMsidAXXid5f/h4GSv9e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"9RAdv_4OsHYW"},"source":["## **내 드라이브 연결** "]},{"cell_type":"code","metadata":{"id":"9qCO_P90r64h"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AAC-W4rPsGr5"},"source":["cd /content/drive/My Drive/myModel"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_D4guUtfsTrf"},"source":["# 현재 경로 확인\n","pwd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M6z8hRn4seWV"},"source":["##**사용할 라이브러리 추가**"]},{"cell_type":"code","metadata":{"id":"uAMqgzJxsfTu"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","\n","import torchvision\n","import torchvision.transforms as transforms"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UOSU3FB-s6Uv"},"source":["# 코랩에서는 외부에 다운받은 라이브러리 import 못하는듯\n","import numpy as np\n","import torch\n","\n","class EarlyStopping:\n","    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n","    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time validation loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each validation loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","            path (str): Path for the checkpoint to be saved to.\n","                            Default: 'checkpoint.pt'\n","            trace_func (function): trace print function.\n","                            Default: print            \n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","        self.trace_func = trace_func\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when validation loss decrease.'''\n","        if self.verbose:\n","            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KcaTSvA_tBOc"},"source":["## **데이터 불러오기**"]},{"cell_type":"code","metadata":{"id":"-VizC9bCtAs_"},"source":["batch_size = 16\n","transform = transforms.Compose([\n","                                transforms.ToTensor(),\n","                                transforms.Resize((64, 64))\n","])\n","\n","train_data = torchvision.datasets.ImageFolder('./train', transform=transform)\n","test_data = torchvision.datasets.ImageFolder('./test', transform=transform)\n","\n","train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)\n","print(train_data)\n","print(test_data)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GMdqmjCDtQLt"},"source":["## **데이터 이미지화**"]},{"cell_type":"code","metadata":{"id":"wt8OOjSytafU"},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","def imgshow(img):\n","    # img = img / 2 + 0.5 # 이미지를 흐려지게 만드려고 \n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0))) # 3차원 데이터라서 transpose할 때 shape 지정해줘야됨\n","    plt.show()\n","\n","dataiter = iter(train_loader) # 원하는 데이터 넣기\n","img, lab = dataiter.next()\n","print(img.shape)\n","\n","imgshow(torchvision.utils.make_grid(img))\n","\n","classes = ('reja1', 'reja2', 'reja3', 'reja4', 'reja5', 'reja6', 'reja7', 'reja8', 'reja9', 'silicon1', 'silicon2', 'silicon3', 'silicon4', 'silicon5', 'silicon6', 'silicon7', 'silicon8', 'silicon9')\n","\n","# label 출력\n","print(' '.join('%s' % classes[lab[i]] for i in range(batch_size)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"32dzlPy5vq4g"},"source":["## **모델 만들기**"]},{"cell_type":"code","metadata":{"id":"XMqji8KXvv22"},"source":["class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.layer = nn.Sequential(\n","            nn.Conv2d(3, 16, 5),\n","            # nn.ReLU(),\n","            nn.BatchNorm2d(16),\n","            nn.LeakyReLU(0.2),\n","\n","            nn.Conv2d(16, 32, 5),\n","            nn.BatchNorm2d(32),\n","            nn.LeakyReLU(0.2),\n","            # nn.ReLU(),\n","            nn.MaxPool2d(2, 2),\n","\n","            nn.Conv2d(32, 64, 5),\n","            nn.BatchNorm2d(64),\n","            nn.LeakyReLU(0.2),\n","            # nn.ReLU(),\n","            nn.MaxPool2d(2, 2)\n","        )\n","\n","        self.fc_layer = nn.Sequential(\n","            nn.Linear(64 * 12 * 12, 100), # shape 계산해서 첫번째 인자 맞춰주기 !!\n","            nn.BatchNorm1d(100), # 2d 하면 에러나씀\n","            nn.LeakyReLU(0.2),\n","            nn.Linear(100, 18) # class 개수로 맞춰주기\n","        )\n","    \n","    def forward(self, x):\n","        out = self.layer(x) # out 형태 (batch_size, channel, row_size, col_size)\n","        out = out.view(out.size(0), -1) # Linear에 들어가기 전 shape 변경\n","        out = self.fc_layer(out) \n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_vcv-577xliG"},"source":["### **장치설정** ( GPU / CPU 환경 설정 )"]},{"cell_type":"code","metadata":{"id":"SRs2b3Wqw0mI"},"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Orf_bjEGx7rx"},"source":["### **모델을 장치로 보내주기**"]},{"cell_type":"code","metadata":{"id":"QmhQaWZ1y-13"},"source":["net = CNN().to(device)\n","net # 모델 정보 출력됨"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SkVaWxD-zNCS"},"source":["## **모델 shape 확인**"]},{"cell_type":"code","metadata":{"id":"5h1N3JPczdh9"},"source":["pip install pytorch-model-summary"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HLQ7CVUyzXFO"},"source":["# 모델 shape 출력\n","import pytorch_model_summary as summary\n","print(summary.summary(net, torch.zeros(batch_size, 3, 64, 64).to(device), show_input = True))\n","print(summary.summary(net, torch.zeros(batch_size, 3, 64, 64).to(device), show_input = False))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EgNLhez3zljZ"},"source":["## **Train**"]},{"cell_type":"markdown","metadata":{"id":"ymh2uQUcztn3"},"source":["### **train 환경 설정**"]},{"cell_type":"code","metadata":{"id":"ridvIOJU4tBZ"},"source":["optimizer = optim.Adam(net.parameters(), lr=0.0001)\n","loss_func = nn.CrossEntropyLoss().to(device)\n","epochs = 100\n","patience = 10\n","data_loader = train_loader"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iBD5R78l41FJ"},"source":["### **학습 시작**"]},{"cell_type":"code","metadata":{"id":"M41ZzM0G5B4M"},"source":["total_batch = len(data_loader) # 한 epoch 당 minibatch 개수\n","\n","for epoch in range(epochs):\n","    net.train()\n","    early_stopping = EarlyStopping(patience = 20, verbose = False)\n","    avg_cost = 0.0     \n","    for i, (inputs, labels) in enumerate(data_loader):\n","      # inputs, labels = data\n","      inputs, labels = inputs.to(device), labels.to(device)\n","\n","      optimizer.zero_grad()\n","      outputs = net(inputs)\n","      loss = loss_func(outputs, labels)\n","      loss.backward()\n","      optimizer.step()\n","        \n","      avg_cost += loss / total_batch\n","\n","    early_stopping(avg_cost, net)\n","    if early_stopping.early_stop:\n","      print(\"early stop !!\")\n","      break\n","\n","    print('[Epoch:{}/{}] cost = {:.6f}'.format(epoch+1, epochs, avg_cost))\n","print('Learning Finished!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M-yO8NX76KLw"},"source":["## **Test**"]},{"cell_type":"markdown","metadata":{"id":"ojh0FZA86NDQ"},"source":["### **데이터 예측하기**"]},{"cell_type":"code","metadata":{"id":"5CU2rAfO6VY8"},"source":["net.eval()\n","# classes = ('reja1', 'reja7', 'reja9', 'silicon1', 'silicon7', 'silicon9')\n","classes = ('reja1', 'reja2', 'reja3', 'reja4', 'reja5', 'reja6', 'reja7', 'reja8', 'reja9', 'silicon1', 'silicon2', 'silicon3', 'silicon4', 'silicon5', 'silicon6', 'silicon7', 'silicon8', 'silicon9')\n","\n","# 이미지 가져오기\n","dataiter = iter(test_loader)\n","img, lab = dataiter.next() # 배치 1개 가져오기, 설정한 배치 사이즈의 개수만큼 가져옴\n","\n","imgshow(torchvision.utils.make_grid(img)) # 이미지로 확인\n","\n","print('<original label>')\n","print(' '.join('%s' % classes[lab[i]] for i in range(batch_size))) # label 확인\n","\n","# 예측하기\n","img, lab = img.to(device), lab.to(device)\n","outputs = net(img)\n","_, predict = torch.max(outputs, 1)\n","\n","print('<predicted label>')\n","print(' '.join('%s' % classes[predict[i]] for i in range(batch_size)))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kSX5Ekuq9fmf"},"source":["### **testset accuracy 출력**"]},{"cell_type":"code","metadata":{"id":"OEZKQcft9YVK"},"source":["print(len(test_loader.dataset))\n","print(len(test_loader))\n","correct = 0\n","total = 0\n","test_loss = 0\n","import matplotlib.pyplot as plt\n","\n","lst = []\n","with torch.no_grad():\n","    for idx, data in enumerate(test_loader):\n","        net.eval()\n","        images, labels = data\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = net(images)\n","\n","        # reduction = 'sum'을 입력해서 미니배치의 합을 받아옴\n","        # 오차의 합 구하기\n","        test_loss += F.cross_entropy(outputs, labels, reduction='sum').item()\n","        test_loss /= len(test_loader.dataset)\n","\n","        _, predicted = torch.max(outputs.data, 1) # 행방향 최대값 // predicted: 최대값 인덱스가 담긴 리스트\n","        # predicted = output.max(1, keepdim=True)[1] 이거랑 같음\n","\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","        print(correct)\n","        lst.append(100 * correct / total)\n","        # plt.plot(idx, idx)\n","        # plt.show()\n","    \n","        print('[{}/{}] Accuracy: {:.2f}% Test Loss: {:.4f}'.format(idx, len(test_loader), 100 * correct / total, test_loss))\n","\n","plt.plot([0,1,2,3,4], lst)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zTziw5a4-qlj"},"source":["### **class 별 testset accuracy 출력**"]},{"cell_type":"code","metadata":{"id":"KrQptiMO-vkE"},"source":["correct_pred = {classname: 0 for classname in classes} # 0으로 초기화 {'plane': 0, 'car': 0, 'bird': 0, 'cat': 0, 'deer': 0, 'dog': 0, 'frog': 0, 'horse': 0, 'ship': 0, 'truck': 0}\n","total_pred = {classname: 0 for classname in classes}\n","# print('correct_pred:', correct_pred)\n","# print('total_pred:', total_pred)\n","\n","with torch.no_grad():\n","    for idx, data in enumerate(test_loader):\n","        net.eval()\n","        images, labels = data\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = net(images)\n","        # outputs.data 랑 outputs 결과 똑같음\n","        _, predicted = torch.max(outputs.data, 1)\n","        # print('pre:', predicted)\n","        for label, prediction in zip(labels, predicted):\n","          if label == prediction:\n","            correct_pred[classes[label]] += 1\n","          total_pred[classes[label]] += 1\n","\n","for classname, correct_count in correct_pred.items():\n","  accuracy = 100 * float(correct_count) / total_pred[classname]\n","  print('Accuracy for class [{:s}] is: {:.1f}%'.format(classname, accuracy)) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j1VbjC8MBIOZ"},"source":["## **모델 저장**"]},{"cell_type":"code","metadata":{"id":"fHRP18CNBPh8"},"source":["# 전체 모델 저장\n","# 모델 파라미터, 옵티마이저, 에포크 등 ...\n","path = './yuminModel.pt'\n","net = CNN()\n","torch.save(net, path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E16OxMyiBUsw"},"source":["# 모델의 매개변수만 저장\n","path = './yuminModel.pth'\n","torch.save(net.state_dict(), path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ndKIIWQOBhad"},"source":["## **모델 불러오기**"]},{"cell_type":"code","metadata":{"id":"egpyZzJBBmPS"},"source":["# 저장한 모델 불러오기\n","net = CNN()\n","path = './yuminModel.pth'\n","net.load_state_dict(torch.load(path))\n","\n","# 모델의 state_dict 출력\n","print(\"Model's state_dict:\")\n","for param_tensor in net.state_dict():\n","    print(param_tensor, \"\\t\", net.state_dict()[param_tensor].size())\n","\n","# # 옵티마이저의 state_dict 출력\n","print(\"Optimizer's state_dict:\")\n","for var_name in optimizer.state_dict():\n","    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"],"execution_count":null,"outputs":[]}]}